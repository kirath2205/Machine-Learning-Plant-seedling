{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant_seedlings_project_attempt_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDJhnYAPb19wUKiV2//vrh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Machine-Learning-Plant-seedling/blob/main/Plant_seedlings_project_vgg_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jLKQK3N4V9-"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ol4ui5dfu1"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRsevFzr5OUZ"
      },
      "source": [
        "def define_generators():\n",
        "  height = 299\n",
        "  width = 299\n",
        "  batch_size = 64\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=360,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        shear_range=0.3,\n",
        "        zoom_range=0.5,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.08, # change to use validation instead of training on entire training set\n",
        "    )\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "        directory='Documents/train',\n",
        "        target_size=(width, height),\n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        class_mode=\"categorical\",\n",
        "        subset='training',\n",
        "    )\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_directory(\n",
        "        directory='Documents/train',\n",
        "        target_size=(width, height),\n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        class_mode=\"categorical\",\n",
        "        subset='validation',\n",
        "    )\n",
        "\n",
        "  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "        directory='Documents/',\n",
        "        classes=['test'],\n",
        "        target_size=(width, height),\n",
        "        batch_size=1,\n",
        "        color_mode='rgb',\n",
        "        shuffle=False,\n",
        "        class_mode='categorical')\n",
        "\n",
        "  return train_generator, validation_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAUpGw6D6ip9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def define_model_vgg19_improvement(image_shape,total_classes):\n",
        "  print(image_shape[2])\n",
        "\n",
        "  model = Sequential()\n",
        "  weight_decay = 0.0005\n",
        "  learning_rate = 0.1\n",
        "  lr_decay = 1e-6\n",
        "  lr_drop = 20\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), padding='same',input_shape=image_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNZV6W7O9s2O"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(model , train_generator,validation_generator,epochs=10):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg19_plant_seedlings_attempt_1', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.9, patience = 3, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 40)\n",
        "  ]\n",
        "  history=model.fit(train_generator, epochs = epochs,callbacks = callbacks, verbose = 1,validation_data = validation_generator)\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ35ZSAIbuNm",
        "outputId": "11a0ef7b-b013-4e24-e09a-835ae078dd82"
      },
      "source": [
        "train_generator, validation_generator, test_generator  = define_generators()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4376 images belonging to 12 classes.\n",
            "Found 374 images belonging to 12 classes.\n",
            "Found 794 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An9BB54h9xY2",
        "outputId": "ce0e77ac-f149-488f-904b-f08ceb8bb9c8"
      },
      "source": [
        "\n",
        "\n",
        "improved_model = define_model_vgg19_improvement((299, 299 , 3),12)\n",
        "history = train_model_vgg16(improved_model , train_generator , validation_generator , epochs=250 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.4046 - accuracy: 0.1319\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.08289, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 75s 2s/step - loss: 14.4046 - accuracy: 0.1319 - val_loss: 598081.4375 - val_accuracy: 0.0829 - lr: 0.1000\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 18.5788 - accuracy: 0.1709\n",
            "Epoch 00002: val_accuracy improved from 0.08289 to 0.12032, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 18.5788 - accuracy: 0.1709 - val_loss: 21901.0332 - val_accuracy: 0.1203 - lr: 0.1000\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 17.1285 - accuracy: 0.2050\n",
            "Epoch 00003: val_accuracy did not improve from 0.12032\n",
            "35/35 [==============================] - 68s 2s/step - loss: 17.1285 - accuracy: 0.2050 - val_loss: 177.8139 - val_accuracy: 0.1123 - lr: 0.1000\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.8100 - accuracy: 0.2189\n",
            "Epoch 00004: val_accuracy did not improve from 0.12032\n",
            "35/35 [==============================] - 68s 2s/step - loss: 15.8100 - accuracy: 0.2189 - val_loss: 34.1800 - val_accuracy: 0.1043 - lr: 0.1000\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.2517 - accuracy: 0.2930\n",
            "Epoch 00005: val_accuracy did not improve from 0.12032\n",
            "35/35 [==============================] - 68s 2s/step - loss: 14.2517 - accuracy: 0.2930 - val_loss: 15.3193 - val_accuracy: 0.1043 - lr: 0.1000\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.3193 - accuracy: 0.3103\n",
            "Epoch 00006: val_accuracy improved from 0.12032 to 0.14439, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 13.3193 - accuracy: 0.3103 - val_loss: 15.2348 - val_accuracy: 0.1444 - lr: 0.1000\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.4951 - accuracy: 0.3247\n",
            "Epoch 00007: val_accuracy did not improve from 0.14439\n",
            "35/35 [==============================] - 68s 2s/step - loss: 12.4951 - accuracy: 0.3247 - val_loss: 14.4747 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 11.7375 - accuracy: 0.3288\n",
            "Epoch 00008: val_accuracy did not improve from 0.14439\n",
            "35/35 [==============================] - 68s 2s/step - loss: 11.7375 - accuracy: 0.3288 - val_loss: 12.9405 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 11.0314 - accuracy: 0.3515\n",
            "Epoch 00009: val_accuracy did not improve from 0.14439\n",
            "35/35 [==============================] - 68s 2s/step - loss: 11.0314 - accuracy: 0.3515 - val_loss: 12.7709 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 10.3507 - accuracy: 0.3679\n",
            "Epoch 00010: val_accuracy did not improve from 0.14439\n",
            "35/35 [==============================] - 68s 2s/step - loss: 10.3507 - accuracy: 0.3679 - val_loss: 12.1386 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.7356 - accuracy: 0.3867\n",
            "Epoch 00011: val_accuracy did not improve from 0.14439\n",
            "35/35 [==============================] - 70s 2s/step - loss: 9.7356 - accuracy: 0.3867 - val_loss: 11.4392 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.1825 - accuracy: 0.3926\n",
            "Epoch 00012: val_accuracy did not improve from 0.14439\n",
            "35/35 [==============================] - 68s 2s/step - loss: 9.1825 - accuracy: 0.3926 - val_loss: 11.1767 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 8.6402 - accuracy: 0.4049\n",
            "Epoch 00013: val_accuracy improved from 0.14439 to 0.14706, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 8.6402 - accuracy: 0.4049 - val_loss: 10.1149 - val_accuracy: 0.1471 - lr: 0.1000\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 8.1277 - accuracy: 0.4232\n",
            "Epoch 00014: val_accuracy improved from 0.14706 to 0.16043, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 8.1277 - accuracy: 0.4232 - val_loss: 9.3880 - val_accuracy: 0.1604 - lr: 0.1000\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 7.6615 - accuracy: 0.4328\n",
            "Epoch 00015: val_accuracy improved from 0.16043 to 0.16578, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 7.6615 - accuracy: 0.4328 - val_loss: 8.9667 - val_accuracy: 0.1658 - lr: 0.1000\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 7.2296 - accuracy: 0.4390\n",
            "Epoch 00016: val_accuracy improved from 0.16578 to 0.20856, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 7.2296 - accuracy: 0.4390 - val_loss: 8.3810 - val_accuracy: 0.2086 - lr: 0.1000\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 6.8124 - accuracy: 0.4723\n",
            "Epoch 00017: val_accuracy did not improve from 0.20856\n",
            "35/35 [==============================] - 68s 2s/step - loss: 6.8124 - accuracy: 0.4723 - val_loss: 8.2399 - val_accuracy: 0.1738 - lr: 0.1000\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 6.4211 - accuracy: 0.4801\n",
            "Epoch 00018: val_accuracy did not improve from 0.20856\n",
            "35/35 [==============================] - 68s 2s/step - loss: 6.4211 - accuracy: 0.4801 - val_loss: 8.1095 - val_accuracy: 0.1310 - lr: 0.1000\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 6.0394 - accuracy: 0.5005\n",
            "Epoch 00019: val_accuracy did not improve from 0.20856\n",
            "35/35 [==============================] - 68s 2s/step - loss: 6.0394 - accuracy: 0.5005 - val_loss: 7.7361 - val_accuracy: 0.1684 - lr: 0.1000\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 5.6861 - accuracy: 0.5347\n",
            "Epoch 00020: val_accuracy did not improve from 0.20856\n",
            "35/35 [==============================] - 68s 2s/step - loss: 5.6861 - accuracy: 0.5347 - val_loss: 7.3760 - val_accuracy: 0.1390 - lr: 0.1000\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 5.3161 - accuracy: 0.5734\n",
            "Epoch 00021: val_accuracy did not improve from 0.20856\n",
            "35/35 [==============================] - 67s 2s/step - loss: 5.3161 - accuracy: 0.5734 - val_loss: 6.8658 - val_accuracy: 0.1604 - lr: 0.1000\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 5.1352 - accuracy: 0.5468\n",
            "Epoch 00022: val_accuracy improved from 0.20856 to 0.27540, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 5.1352 - accuracy: 0.5468 - val_loss: 6.2398 - val_accuracy: 0.2754 - lr: 0.1000\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 4.8058 - accuracy: 0.5770\n",
            "Epoch 00023: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 68s 2s/step - loss: 4.8058 - accuracy: 0.5770 - val_loss: 8.1407 - val_accuracy: 0.0508 - lr: 0.1000\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 4.5318 - accuracy: 0.5880\n",
            "Epoch 00024: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 4.5318 - accuracy: 0.5880 - val_loss: 6.6948 - val_accuracy: 0.0989 - lr: 0.1000\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 4.2561 - accuracy: 0.6209\n",
            "Epoch 00025: val_accuracy did not improve from 0.27540\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.09000000134110452.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 4.2561 - accuracy: 0.6209 - val_loss: 9.6722 - val_accuracy: 0.0455 - lr: 0.1000\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 4.0195 - accuracy: 0.6376\n",
            "Epoch 00026: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 68s 2s/step - loss: 4.0195 - accuracy: 0.6376 - val_loss: 7.1710 - val_accuracy: 0.0775 - lr: 0.0900\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 3.7754 - accuracy: 0.6634\n",
            "Epoch 00027: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 68s 2s/step - loss: 3.7754 - accuracy: 0.6634 - val_loss: 7.2871 - val_accuracy: 0.0722 - lr: 0.0900\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 3.6286 - accuracy: 0.6634\n",
            "Epoch 00028: val_accuracy did not improve from 0.27540\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.08100000321865082.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 3.6286 - accuracy: 0.6634 - val_loss: 8.1239 - val_accuracy: 0.0481 - lr: 0.0900\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 3.4056 - accuracy: 0.6917\n",
            "Epoch 00029: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 3.4056 - accuracy: 0.6917 - val_loss: 7.3632 - val_accuracy: 0.0749 - lr: 0.0810\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 3.2543 - accuracy: 0.7068\n",
            "Epoch 00030: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 68s 2s/step - loss: 3.2543 - accuracy: 0.7068 - val_loss: 5.9156 - val_accuracy: 0.1150 - lr: 0.0810\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 3.1393 - accuracy: 0.7038\n",
            "Epoch 00031: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 3.1393 - accuracy: 0.7038 - val_loss: 5.6987 - val_accuracy: 0.1658 - lr: 0.0810\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 3.0238 - accuracy: 0.7109\n",
            "Epoch 00032: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 3.0238 - accuracy: 0.7109 - val_loss: 5.5028 - val_accuracy: 0.1578 - lr: 0.0810\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.8670 - accuracy: 0.7356\n",
            "Epoch 00033: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.8670 - accuracy: 0.7356 - val_loss: 7.1999 - val_accuracy: 0.1043 - lr: 0.0810\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.7928 - accuracy: 0.7137\n",
            "Epoch 00034: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.7928 - accuracy: 0.7137 - val_loss: 8.1656 - val_accuracy: 0.0642 - lr: 0.0810\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.6656 - accuracy: 0.7329\n",
            "Epoch 00035: val_accuracy did not improve from 0.27540\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.07290000021457672.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 2.6656 - accuracy: 0.7329 - val_loss: 7.1256 - val_accuracy: 0.1016 - lr: 0.0810\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.5757 - accuracy: 0.7411\n",
            "Epoch 00036: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.5757 - accuracy: 0.7411 - val_loss: 4.9918 - val_accuracy: 0.2112 - lr: 0.0729\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.4688 - accuracy: 0.7470\n",
            "Epoch 00037: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.4688 - accuracy: 0.7470 - val_loss: 4.5192 - val_accuracy: 0.2647 - lr: 0.0729\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.3686 - accuracy: 0.7614\n",
            "Epoch 00038: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.3686 - accuracy: 0.7614 - val_loss: 6.2969 - val_accuracy: 0.1604 - lr: 0.0729\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.2091 - accuracy: 0.7952\n",
            "Epoch 00039: val_accuracy did not improve from 0.27540\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.2091 - accuracy: 0.7952 - val_loss: 5.4858 - val_accuracy: 0.1096 - lr: 0.0729\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.1565 - accuracy: 0.7943\n",
            "Epoch 00040: val_accuracy improved from 0.27540 to 0.30749, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 2.1565 - accuracy: 0.7943 - val_loss: 3.9230 - val_accuracy: 0.3075 - lr: 0.0729\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.0590 - accuracy: 0.8030\n",
            "Epoch 00041: val_accuracy did not improve from 0.30749\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.0590 - accuracy: 0.8030 - val_loss: 6.4862 - val_accuracy: 0.1738 - lr: 0.0729\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.0838 - accuracy: 0.7781\n",
            "Epoch 00042: val_accuracy improved from 0.30749 to 0.33690, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 2.0838 - accuracy: 0.7781 - val_loss: 3.8543 - val_accuracy: 0.3369 - lr: 0.0729\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.0023 - accuracy: 0.7831\n",
            "Epoch 00043: val_accuracy did not improve from 0.33690\n",
            "35/35 [==============================] - 67s 2s/step - loss: 2.0023 - accuracy: 0.7831 - val_loss: 6.4147 - val_accuracy: 0.1658 - lr: 0.0729\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.8857 - accuracy: 0.8133\n",
            "Epoch 00044: val_accuracy improved from 0.33690 to 0.34759, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 1.8857 - accuracy: 0.8133 - val_loss: 3.4935 - val_accuracy: 0.3476 - lr: 0.0729\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.8187 - accuracy: 0.8078\n",
            "Epoch 00045: val_accuracy did not improve from 0.34759\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.8187 - accuracy: 0.8078 - val_loss: 8.4139 - val_accuracy: 0.1043 - lr: 0.0729\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.7634 - accuracy: 0.8112\n",
            "Epoch 00046: val_accuracy did not improve from 0.34759\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.7634 - accuracy: 0.8112 - val_loss: 4.9072 - val_accuracy: 0.2754 - lr: 0.0729\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.7212 - accuracy: 0.8087\n",
            "Epoch 00047: val_accuracy did not improve from 0.34759\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.06560999751091004.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.7212 - accuracy: 0.8087 - val_loss: 4.0803 - val_accuracy: 0.3048 - lr: 0.0729\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.6388 - accuracy: 0.8330\n",
            "Epoch 00048: val_accuracy improved from 0.34759 to 0.42513, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 1.6388 - accuracy: 0.8330 - val_loss: 3.0959 - val_accuracy: 0.4251 - lr: 0.0656\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5852 - accuracy: 0.8261\n",
            "Epoch 00049: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.5852 - accuracy: 0.8261 - val_loss: 4.1556 - val_accuracy: 0.2754 - lr: 0.0656\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5366 - accuracy: 0.8343\n",
            "Epoch 00050: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.5366 - accuracy: 0.8343 - val_loss: 5.8238 - val_accuracy: 0.2380 - lr: 0.0656\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5616 - accuracy: 0.8204\n",
            "Epoch 00051: val_accuracy did not improve from 0.42513\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.05904899910092354.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.5616 - accuracy: 0.8204 - val_loss: 4.0786 - val_accuracy: 0.2594 - lr: 0.0656\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.4730 - accuracy: 0.8384\n",
            "Epoch 00052: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.4730 - accuracy: 0.8384 - val_loss: 4.9645 - val_accuracy: 0.2540 - lr: 0.0590\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.4050 - accuracy: 0.8471\n",
            "Epoch 00053: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.4050 - accuracy: 0.8471 - val_loss: 6.6709 - val_accuracy: 0.2754 - lr: 0.0590\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3813 - accuracy: 0.8464\n",
            "Epoch 00054: val_accuracy did not improve from 0.42513\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.053144099190831184.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.3813 - accuracy: 0.8464 - val_loss: 4.5300 - val_accuracy: 0.2674 - lr: 0.0590\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3295 - accuracy: 0.8528\n",
            "Epoch 00055: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.3295 - accuracy: 0.8528 - val_loss: 5.1278 - val_accuracy: 0.2246 - lr: 0.0531\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3013 - accuracy: 0.8569\n",
            "Epoch 00056: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.3013 - accuracy: 0.8569 - val_loss: 7.8083 - val_accuracy: 0.2005 - lr: 0.0531\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3142 - accuracy: 0.8455\n",
            "Epoch 00057: val_accuracy did not improve from 0.42513\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.04782968759536743.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.3142 - accuracy: 0.8455 - val_loss: 4.8449 - val_accuracy: 0.3021 - lr: 0.0531\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2305 - accuracy: 0.8695\n",
            "Epoch 00058: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.2305 - accuracy: 0.8695 - val_loss: 4.8129 - val_accuracy: 0.2861 - lr: 0.0478\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2074 - accuracy: 0.8679\n",
            "Epoch 00059: val_accuracy did not improve from 0.42513\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.2074 - accuracy: 0.8679 - val_loss: 4.0517 - val_accuracy: 0.3102 - lr: 0.0478\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2051 - accuracy: 0.8636\n",
            "Epoch 00060: val_accuracy did not improve from 0.42513\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.04304671883583069.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.2051 - accuracy: 0.8636 - val_loss: 4.5867 - val_accuracy: 0.3316 - lr: 0.0478\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1618 - accuracy: 0.8741\n",
            "Epoch 00061: val_accuracy improved from 0.42513 to 0.50267, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 1.1618 - accuracy: 0.8741 - val_loss: 2.6887 - val_accuracy: 0.5027 - lr: 0.0430\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1655 - accuracy: 0.8670\n",
            "Epoch 00062: val_accuracy did not improve from 0.50267\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.1655 - accuracy: 0.8670 - val_loss: 4.7991 - val_accuracy: 0.2086 - lr: 0.0430\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1231 - accuracy: 0.8780\n",
            "Epoch 00063: val_accuracy did not improve from 0.50267\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.1231 - accuracy: 0.8780 - val_loss: 2.7339 - val_accuracy: 0.3717 - lr: 0.0430\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0865 - accuracy: 0.8773\n",
            "Epoch 00064: val_accuracy improved from 0.50267 to 0.57754, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 1.0865 - accuracy: 0.8773 - val_loss: 2.1911 - val_accuracy: 0.5775 - lr: 0.0430\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.8805\n",
            "Epoch 00065: val_accuracy did not improve from 0.57754\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.0777 - accuracy: 0.8805 - val_loss: 3.3604 - val_accuracy: 0.4278 - lr: 0.0430\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0553 - accuracy: 0.8851\n",
            "Epoch 00066: val_accuracy did not improve from 0.57754\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.0553 - accuracy: 0.8851 - val_loss: 3.2239 - val_accuracy: 0.3235 - lr: 0.0430\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0508 - accuracy: 0.8741\n",
            "Epoch 00067: val_accuracy improved from 0.57754 to 0.71123, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 1.0508 - accuracy: 0.8741 - val_loss: 1.6441 - val_accuracy: 0.7112 - lr: 0.0430\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0053 - accuracy: 0.8885\n",
            "Epoch 00068: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 67s 2s/step - loss: 1.0053 - accuracy: 0.8885 - val_loss: 2.6473 - val_accuracy: 0.5107 - lr: 0.0430\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.8876\n",
            "Epoch 00069: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.9919 - accuracy: 0.8876 - val_loss: 2.9091 - val_accuracy: 0.5027 - lr: 0.0430\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.8787\n",
            "Epoch 00070: val_accuracy did not improve from 0.71123\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.03874204829335213.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.0049 - accuracy: 0.8787 - val_loss: 2.9597 - val_accuracy: 0.4545 - lr: 0.0430\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0632 - accuracy: 0.8585\n",
            "Epoch 00071: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 68s 2s/step - loss: 1.0632 - accuracy: 0.8585 - val_loss: 8.4066 - val_accuracy: 0.1898 - lr: 0.0387\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9858 - accuracy: 0.8814\n",
            "Epoch 00072: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.9858 - accuracy: 0.8814 - val_loss: 1.5961 - val_accuracy: 0.6738 - lr: 0.0387\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9628 - accuracy: 0.8871\n",
            "Epoch 00073: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.9628 - accuracy: 0.8871 - val_loss: 2.7970 - val_accuracy: 0.4679 - lr: 0.0387\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9132 - accuracy: 0.8960\n",
            "Epoch 00074: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.9132 - accuracy: 0.8960 - val_loss: 2.6862 - val_accuracy: 0.4813 - lr: 0.0387\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9432 - accuracy: 0.8846\n",
            "Epoch 00075: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.9432 - accuracy: 0.8846 - val_loss: 1.5418 - val_accuracy: 0.6979 - lr: 0.0387\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9281 - accuracy: 0.8867\n",
            "Epoch 00076: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.9281 - accuracy: 0.8867 - val_loss: 2.7744 - val_accuracy: 0.4385 - lr: 0.0387\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8915 - accuracy: 0.8928\n",
            "Epoch 00077: val_accuracy did not improve from 0.71123\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.8915 - accuracy: 0.8928 - val_loss: 3.5789 - val_accuracy: 0.4037 - lr: 0.0387\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8743 - accuracy: 0.9020\n",
            "Epoch 00078: val_accuracy improved from 0.71123 to 0.72727, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.8743 - accuracy: 0.9020 - val_loss: 1.4713 - val_accuracy: 0.7273 - lr: 0.0387\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.8940\n",
            "Epoch 00079: val_accuracy did not improve from 0.72727\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.8852 - accuracy: 0.8940 - val_loss: 2.3207 - val_accuracy: 0.5481 - lr: 0.0387\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.8919\n",
            "Epoch 00080: val_accuracy did not improve from 0.72727\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.8694 - accuracy: 0.8919 - val_loss: 4.4789 - val_accuracy: 0.3128 - lr: 0.0387\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8624 - accuracy: 0.8933\n",
            "Epoch 00081: val_accuracy did not improve from 0.72727\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.034867842122912406.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.8624 - accuracy: 0.8933 - val_loss: 2.9525 - val_accuracy: 0.3877 - lr: 0.0387\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8312 - accuracy: 0.9004\n",
            "Epoch 00082: val_accuracy improved from 0.72727 to 0.73262, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 0.8312 - accuracy: 0.9004 - val_loss: 1.3750 - val_accuracy: 0.7326 - lr: 0.0349\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7894 - accuracy: 0.9088\n",
            "Epoch 00083: val_accuracy did not improve from 0.73262\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.7894 - accuracy: 0.9088 - val_loss: 2.0331 - val_accuracy: 0.5856 - lr: 0.0349\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.9065\n",
            "Epoch 00084: val_accuracy improved from 0.73262 to 0.79144, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.7969 - accuracy: 0.9065 - val_loss: 1.1686 - val_accuracy: 0.7914 - lr: 0.0349\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7858 - accuracy: 0.9129\n",
            "Epoch 00085: val_accuracy did not improve from 0.79144\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.7858 - accuracy: 0.9129 - val_loss: 5.4782 - val_accuracy: 0.2567 - lr: 0.0349\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7902 - accuracy: 0.9029\n",
            "Epoch 00086: val_accuracy did not improve from 0.79144\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.7902 - accuracy: 0.9029 - val_loss: 1.6162 - val_accuracy: 0.6604 - lr: 0.0349\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7416 - accuracy: 0.9182\n",
            "Epoch 00087: val_accuracy did not improve from 0.79144\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.03138105757534504.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.7416 - accuracy: 0.9182 - val_loss: 1.4397 - val_accuracy: 0.7246 - lr: 0.0349\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.9132\n",
            "Epoch 00088: val_accuracy did not improve from 0.79144\n",
            "35/35 [==============================] - 66s 2s/step - loss: 0.7455 - accuracy: 0.9132 - val_loss: 2.7830 - val_accuracy: 0.4599 - lr: 0.0314\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8208 - accuracy: 0.8839\n",
            "Epoch 00089: val_accuracy did not improve from 0.79144\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.8208 - accuracy: 0.8839 - val_loss: 2.3036 - val_accuracy: 0.5508 - lr: 0.0314\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7490 - accuracy: 0.9102\n",
            "Epoch 00090: val_accuracy improved from 0.79144 to 0.82086, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.7490 - accuracy: 0.9102 - val_loss: 1.0741 - val_accuracy: 0.8209 - lr: 0.0314\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7329 - accuracy: 0.9157\n",
            "Epoch 00091: val_accuracy did not improve from 0.82086\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.7329 - accuracy: 0.9157 - val_loss: 4.0884 - val_accuracy: 0.3690 - lr: 0.0314\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.9074\n",
            "Epoch 00092: val_accuracy did not improve from 0.82086\n",
            "35/35 [==============================] - 66s 2s/step - loss: 0.7376 - accuracy: 0.9074 - val_loss: 1.4391 - val_accuracy: 0.7380 - lr: 0.0314\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7237 - accuracy: 0.9109\n",
            "Epoch 00093: val_accuracy did not improve from 0.82086\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.028242950141429902.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.7237 - accuracy: 0.9109 - val_loss: 3.0458 - val_accuracy: 0.4545 - lr: 0.0314\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7100 - accuracy: 0.9154\n",
            "Epoch 00094: val_accuracy did not improve from 0.82086\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.7100 - accuracy: 0.9154 - val_loss: 2.5835 - val_accuracy: 0.6043 - lr: 0.0282\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.9143\n",
            "Epoch 00095: val_accuracy did not improve from 0.82086\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.7137 - accuracy: 0.9143 - val_loss: 4.1667 - val_accuracy: 0.4358 - lr: 0.0282\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.9212\n",
            "Epoch 00096: val_accuracy did not improve from 0.82086\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.02541865445673466.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6691 - accuracy: 0.9212 - val_loss: 2.4641 - val_accuracy: 0.5882 - lr: 0.0282\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.9244\n",
            "Epoch 00097: val_accuracy did not improve from 0.82086\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6605 - accuracy: 0.9244 - val_loss: 1.3931 - val_accuracy: 0.7219 - lr: 0.0254\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.9260\n",
            "Epoch 00098: val_accuracy did not improve from 0.82086\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6603 - accuracy: 0.9260 - val_loss: 1.1932 - val_accuracy: 0.7674 - lr: 0.0254\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.9326\n",
            "Epoch 00099: val_accuracy did not improve from 0.82086\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.022876788675785065.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6512 - accuracy: 0.9326 - val_loss: 1.4518 - val_accuracy: 0.6711 - lr: 0.0254\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.9244\n",
            "Epoch 00100: val_accuracy improved from 0.82086 to 0.85294, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.6571 - accuracy: 0.9244 - val_loss: 0.9136 - val_accuracy: 0.8529 - lr: 0.0229\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.9330\n",
            "Epoch 00101: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6188 - accuracy: 0.9330 - val_loss: 2.2151 - val_accuracy: 0.5615 - lr: 0.0229\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.9326\n",
            "Epoch 00102: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.6263 - accuracy: 0.9326 - val_loss: 1.0096 - val_accuracy: 0.8155 - lr: 0.0229\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.9351\n",
            "Epoch 00103: val_accuracy did not improve from 0.85294\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.020589109137654306.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5980 - accuracy: 0.9351 - val_loss: 1.3079 - val_accuracy: 0.7380 - lr: 0.0229\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.9342\n",
            "Epoch 00104: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.6136 - accuracy: 0.9342 - val_loss: 1.2979 - val_accuracy: 0.7406 - lr: 0.0206\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.9257\n",
            "Epoch 00105: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6126 - accuracy: 0.9257 - val_loss: 2.0788 - val_accuracy: 0.5775 - lr: 0.0206\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.9244\n",
            "Epoch 00106: val_accuracy did not improve from 0.85294\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.018530198559165.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.6133 - accuracy: 0.9244 - val_loss: 2.4786 - val_accuracy: 0.5160 - lr: 0.0206\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5949 - accuracy: 0.9282\n",
            "Epoch 00107: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5949 - accuracy: 0.9282 - val_loss: 1.0931 - val_accuracy: 0.8155 - lr: 0.0185\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.9358\n",
            "Epoch 00108: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5739 - accuracy: 0.9358 - val_loss: 1.3003 - val_accuracy: 0.7299 - lr: 0.0185\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.9369\n",
            "Epoch 00109: val_accuracy did not improve from 0.85294\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.016677179373800755.\n",
            "35/35 [==============================] - 70s 2s/step - loss: 0.5787 - accuracy: 0.9369 - val_loss: 1.1483 - val_accuracy: 0.7594 - lr: 0.0185\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.9367\n",
            "Epoch 00110: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5722 - accuracy: 0.9367 - val_loss: 1.2397 - val_accuracy: 0.7380 - lr: 0.0167\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.9262\n",
            "Epoch 00111: val_accuracy did not improve from 0.85294\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5946 - accuracy: 0.9262 - val_loss: 1.3150 - val_accuracy: 0.6845 - lr: 0.0167\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.9358\n",
            "Epoch 00112: val_accuracy improved from 0.85294 to 0.87166, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 0.5574 - accuracy: 0.9358 - val_loss: 0.8022 - val_accuracy: 0.8717 - lr: 0.0167\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.9374\n",
            "Epoch 00113: val_accuracy did not improve from 0.87166\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5475 - accuracy: 0.9374 - val_loss: 1.1900 - val_accuracy: 0.7647 - lr: 0.0167\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.9356\n",
            "Epoch 00114: val_accuracy improved from 0.87166 to 0.89840, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.5603 - accuracy: 0.9356 - val_loss: 0.7211 - val_accuracy: 0.8984 - lr: 0.0167\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.9381\n",
            "Epoch 00115: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5524 - accuracy: 0.9381 - val_loss: 0.8034 - val_accuracy: 0.8797 - lr: 0.0167\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.9394\n",
            "Epoch 00116: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5486 - accuracy: 0.9394 - val_loss: 0.9472 - val_accuracy: 0.8342 - lr: 0.0167\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.9374\n",
            "Epoch 00117: val_accuracy did not improve from 0.89840\n",
            "\n",
            "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.015009460598230362.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5529 - accuracy: 0.9374 - val_loss: 1.0698 - val_accuracy: 0.7888 - lr: 0.0167\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.9342\n",
            "Epoch 00118: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5447 - accuracy: 0.9342 - val_loss: 1.0411 - val_accuracy: 0.8075 - lr: 0.0150\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.9269\n",
            "Epoch 00119: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5702 - accuracy: 0.9269 - val_loss: 1.4001 - val_accuracy: 0.6765 - lr: 0.0150\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.9285\n",
            "Epoch 00120: val_accuracy did not improve from 0.89840\n",
            "\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.013508514873683453.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5628 - accuracy: 0.9285 - val_loss: 0.9200 - val_accuracy: 0.8422 - lr: 0.0150\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.9308\n",
            "Epoch 00121: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5522 - accuracy: 0.9308 - val_loss: 2.5403 - val_accuracy: 0.5668 - lr: 0.0135\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.9392\n",
            "Epoch 00122: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5306 - accuracy: 0.9392 - val_loss: 0.8011 - val_accuracy: 0.8556 - lr: 0.0135\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.9449\n",
            "Epoch 00123: val_accuracy did not improve from 0.89840\n",
            "\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.012157663051038981.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5089 - accuracy: 0.9449 - val_loss: 1.0858 - val_accuracy: 0.7861 - lr: 0.0135\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.9415\n",
            "Epoch 00124: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.5131 - accuracy: 0.9415 - val_loss: 0.8007 - val_accuracy: 0.8556 - lr: 0.0122\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.9454\n",
            "Epoch 00125: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.5112 - accuracy: 0.9454 - val_loss: 0.7746 - val_accuracy: 0.8743 - lr: 0.0122\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.9463\n",
            "Epoch 00126: val_accuracy did not improve from 0.89840\n",
            "\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.010941896494477988.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4957 - accuracy: 0.9463 - val_loss: 0.9456 - val_accuracy: 0.8342 - lr: 0.0122\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.9468\n",
            "Epoch 00127: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4999 - accuracy: 0.9468 - val_loss: 0.8097 - val_accuracy: 0.8930 - lr: 0.0109\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.9472\n",
            "Epoch 00128: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4845 - accuracy: 0.9472 - val_loss: 0.6844 - val_accuracy: 0.8904 - lr: 0.0109\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.9522\n",
            "Epoch 00129: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4875 - accuracy: 0.9522 - val_loss: 0.8456 - val_accuracy: 0.8583 - lr: 0.0109\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.9484\n",
            "Epoch 00130: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4965 - accuracy: 0.9484 - val_loss: 2.8998 - val_accuracy: 0.4786 - lr: 0.0109\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.9463\n",
            "Epoch 00131: val_accuracy did not improve from 0.89840\n",
            "\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.009847706928849221.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4890 - accuracy: 0.9463 - val_loss: 0.6980 - val_accuracy: 0.8984 - lr: 0.0109\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.9497\n",
            "Epoch 00132: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4904 - accuracy: 0.9497 - val_loss: 1.2949 - val_accuracy: 0.7406 - lr: 0.0098\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.9495\n",
            "Epoch 00133: val_accuracy did not improve from 0.89840\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4788 - accuracy: 0.9495 - val_loss: 0.7608 - val_accuracy: 0.8717 - lr: 0.0098\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.9424\n",
            "Epoch 00134: val_accuracy improved from 0.89840 to 0.90642, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.4794 - accuracy: 0.9424 - val_loss: 0.6463 - val_accuracy: 0.9064 - lr: 0.0098\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.9525\n",
            "Epoch 00135: val_accuracy did not improve from 0.90642\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4771 - accuracy: 0.9525 - val_loss: 0.7662 - val_accuracy: 0.8850 - lr: 0.0098\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.9463\n",
            "Epoch 00136: val_accuracy did not improve from 0.90642\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4821 - accuracy: 0.9463 - val_loss: 0.7389 - val_accuracy: 0.8770 - lr: 0.0098\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.9504\n",
            "Epoch 00137: val_accuracy did not improve from 0.90642\n",
            "\n",
            "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.008862936403602362.\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.4728 - accuracy: 0.9504 - val_loss: 0.7931 - val_accuracy: 0.8556 - lr: 0.0098\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.9493\n",
            "Epoch 00138: val_accuracy did not improve from 0.90642\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4730 - accuracy: 0.9493 - val_loss: 0.7262 - val_accuracy: 0.8930 - lr: 0.0089\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.9570\n",
            "Epoch 00139: val_accuracy improved from 0.90642 to 0.92246, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 0.4556 - accuracy: 0.9570 - val_loss: 0.5854 - val_accuracy: 0.9225 - lr: 0.0089\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.9516\n",
            "Epoch 00140: val_accuracy did not improve from 0.92246\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4627 - accuracy: 0.9516 - val_loss: 1.5464 - val_accuracy: 0.6979 - lr: 0.0089\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.9529\n",
            "Epoch 00141: val_accuracy did not improve from 0.92246\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4534 - accuracy: 0.9529 - val_loss: 0.6932 - val_accuracy: 0.8797 - lr: 0.0089\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.9564\n",
            "Epoch 00142: val_accuracy did not improve from 0.92246\n",
            "\n",
            "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.007976643182337284.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4495 - accuracy: 0.9564 - val_loss: 0.8481 - val_accuracy: 0.8369 - lr: 0.0089\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.9490\n",
            "Epoch 00143: val_accuracy did not improve from 0.92246\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4640 - accuracy: 0.9490 - val_loss: 0.6731 - val_accuracy: 0.9091 - lr: 0.0080\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.9511\n",
            "Epoch 00144: val_accuracy did not improve from 0.92246\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4513 - accuracy: 0.9511 - val_loss: 0.6093 - val_accuracy: 0.9091 - lr: 0.0080\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.9488\n",
            "Epoch 00145: val_accuracy did not improve from 0.92246\n",
            "\n",
            "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.007178978528827429.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4594 - accuracy: 0.9488 - val_loss: 0.8852 - val_accuracy: 0.8289 - lr: 0.0080\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.9570\n",
            "Epoch 00146: val_accuracy did not improve from 0.92246\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4418 - accuracy: 0.9570 - val_loss: 0.9292 - val_accuracy: 0.8289 - lr: 0.0072\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.9552\n",
            "Epoch 00147: val_accuracy did not improve from 0.92246\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.4442 - accuracy: 0.9552 - val_loss: 0.7364 - val_accuracy: 0.8797 - lr: 0.0072\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.9616\n",
            "Epoch 00148: val_accuracy improved from 0.92246 to 0.92513, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "\n",
            "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.006461080675944686.\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.4231 - accuracy: 0.9616 - val_loss: 0.6622 - val_accuracy: 0.9251 - lr: 0.0072\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.9550\n",
            "Epoch 00149: val_accuracy did not improve from 0.92513\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4399 - accuracy: 0.9550 - val_loss: 0.6525 - val_accuracy: 0.9037 - lr: 0.0065\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.9589\n",
            "Epoch 00150: val_accuracy did not improve from 0.92513\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4298 - accuracy: 0.9589 - val_loss: 0.6138 - val_accuracy: 0.9144 - lr: 0.0065\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.9630\n",
            "Epoch 00151: val_accuracy did not improve from 0.92513\n",
            "\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.0058149725664407015.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4226 - accuracy: 0.9630 - val_loss: 0.6532 - val_accuracy: 0.9011 - lr: 0.0065\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.9607\n",
            "Epoch 00152: val_accuracy improved from 0.92513 to 0.92781, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.4199 - accuracy: 0.9607 - val_loss: 0.5799 - val_accuracy: 0.9278 - lr: 0.0058\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.9623\n",
            "Epoch 00153: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4179 - accuracy: 0.9623 - val_loss: 0.5823 - val_accuracy: 0.9144 - lr: 0.0058\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.9596\n",
            "Epoch 00154: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4182 - accuracy: 0.9596 - val_loss: 0.6537 - val_accuracy: 0.9037 - lr: 0.0058\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.9609\n",
            "Epoch 00155: val_accuracy did not improve from 0.92781\n",
            "\n",
            "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.005233475100249053.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4146 - accuracy: 0.9609 - val_loss: 1.4627 - val_accuracy: 0.6765 - lr: 0.0058\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.9575\n",
            "Epoch 00156: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4257 - accuracy: 0.9575 - val_loss: 0.9629 - val_accuracy: 0.8289 - lr: 0.0052\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4100 - accuracy: 0.9634\n",
            "Epoch 00157: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4100 - accuracy: 0.9634 - val_loss: 0.6008 - val_accuracy: 0.9171 - lr: 0.0052\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.9641\n",
            "Epoch 00158: val_accuracy did not improve from 0.92781\n",
            "\n",
            "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.0047101275064051155.\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.4111 - accuracy: 0.9641 - val_loss: 0.6154 - val_accuracy: 0.9225 - lr: 0.0052\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.9630\n",
            "Epoch 00159: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.4157 - accuracy: 0.9630 - val_loss: 0.7510 - val_accuracy: 0.8717 - lr: 0.0047\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.9609\n",
            "Epoch 00160: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4062 - accuracy: 0.9609 - val_loss: 0.6034 - val_accuracy: 0.9118 - lr: 0.0047\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.9625\n",
            "Epoch 00161: val_accuracy did not improve from 0.92781\n",
            "\n",
            "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.004239114839583636.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.4115 - accuracy: 0.9625 - val_loss: 0.6509 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.9666\n",
            "Epoch 00162: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3997 - accuracy: 0.9666 - val_loss: 0.5983 - val_accuracy: 0.9225 - lr: 0.0042\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.9664\n",
            "Epoch 00163: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3924 - accuracy: 0.9664 - val_loss: 0.6830 - val_accuracy: 0.8930 - lr: 0.0042\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.9694\n",
            "Epoch 00164: val_accuracy did not improve from 0.92781\n",
            "\n",
            "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.0038152034394443035.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3850 - accuracy: 0.9694 - val_loss: 0.6907 - val_accuracy: 0.8957 - lr: 0.0042\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.9682\n",
            "Epoch 00165: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3927 - accuracy: 0.9682 - val_loss: 0.7637 - val_accuracy: 0.8770 - lr: 0.0038\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.9669\n",
            "Epoch 00166: val_accuracy did not improve from 0.92781\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3921 - accuracy: 0.9669 - val_loss: 0.7670 - val_accuracy: 0.8904 - lr: 0.0038\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.9719\n",
            "Epoch 00167: val_accuracy improved from 0.92781 to 0.93316, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 0.3800 - accuracy: 0.9719 - val_loss: 0.5687 - val_accuracy: 0.9332 - lr: 0.0038\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.9621\n",
            "Epoch 00168: val_accuracy did not improve from 0.93316\n",
            "35/35 [==============================] - 70s 2s/step - loss: 0.4020 - accuracy: 0.9621 - val_loss: 0.5805 - val_accuracy: 0.9305 - lr: 0.0038\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.9644\n",
            "Epoch 00169: val_accuracy did not improve from 0.93316\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3963 - accuracy: 0.9644 - val_loss: 0.6587 - val_accuracy: 0.9171 - lr: 0.0038\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.9653\n",
            "Epoch 00170: val_accuracy did not improve from 0.93316\n",
            "\n",
            "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.003433683095499873.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3915 - accuracy: 0.9653 - val_loss: 0.6241 - val_accuracy: 0.9198 - lr: 0.0038\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.9634\n",
            "Epoch 00171: val_accuracy improved from 0.93316 to 0.93583, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.3987 - accuracy: 0.9634 - val_loss: 0.5554 - val_accuracy: 0.9358 - lr: 0.0034\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.9673\n",
            "Epoch 00172: val_accuracy did not improve from 0.93583\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3799 - accuracy: 0.9673 - val_loss: 0.6173 - val_accuracy: 0.9144 - lr: 0.0034\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.9662\n",
            "Epoch 00173: val_accuracy improved from 0.93583 to 0.95187, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 72s 2s/step - loss: 0.3780 - accuracy: 0.9662 - val_loss: 0.5475 - val_accuracy: 0.9519 - lr: 0.0034\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.9664\n",
            "Epoch 00174: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3872 - accuracy: 0.9664 - val_loss: 0.5773 - val_accuracy: 0.9278 - lr: 0.0034\n",
            "Epoch 175/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.9623\n",
            "Epoch 00175: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3985 - accuracy: 0.9623 - val_loss: 0.6089 - val_accuracy: 0.9305 - lr: 0.0034\n",
            "Epoch 176/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.9660\n",
            "Epoch 00176: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0030903148697689177.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3859 - accuracy: 0.9660 - val_loss: 0.5775 - val_accuracy: 0.9358 - lr: 0.0034\n",
            "Epoch 177/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.9650\n",
            "Epoch 00177: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3801 - accuracy: 0.9650 - val_loss: 0.5671 - val_accuracy: 0.9225 - lr: 0.0031\n",
            "Epoch 178/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.9685\n",
            "Epoch 00178: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.3794 - accuracy: 0.9685 - val_loss: 0.5863 - val_accuracy: 0.9358 - lr: 0.0031\n",
            "Epoch 179/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.9662\n",
            "Epoch 00179: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.002781283319927752.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3745 - accuracy: 0.9662 - val_loss: 0.6166 - val_accuracy: 0.9118 - lr: 0.0031\n",
            "Epoch 180/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.9714\n",
            "Epoch 00180: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3744 - accuracy: 0.9714 - val_loss: 0.5279 - val_accuracy: 0.9492 - lr: 0.0028\n",
            "Epoch 181/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.9733\n",
            "Epoch 00181: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3719 - accuracy: 0.9733 - val_loss: 0.5297 - val_accuracy: 0.9439 - lr: 0.0028\n",
            "Epoch 182/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.9669\n",
            "Epoch 00182: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3897 - accuracy: 0.9669 - val_loss: 0.5667 - val_accuracy: 0.9278 - lr: 0.0028\n",
            "Epoch 183/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.9666\n",
            "Epoch 00183: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.002503155008889735.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3790 - accuracy: 0.9666 - val_loss: 0.6053 - val_accuracy: 0.9251 - lr: 0.0028\n",
            "Epoch 184/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.9662\n",
            "Epoch 00184: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3859 - accuracy: 0.9662 - val_loss: 0.5746 - val_accuracy: 0.9332 - lr: 0.0025\n",
            "Epoch 185/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.9719\n",
            "Epoch 00185: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3618 - accuracy: 0.9719 - val_loss: 0.5008 - val_accuracy: 0.9492 - lr: 0.0025\n",
            "Epoch 186/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.9730\n",
            "Epoch 00186: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3588 - accuracy: 0.9730 - val_loss: 0.5374 - val_accuracy: 0.9171 - lr: 0.0025\n",
            "Epoch 187/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.9717\n",
            "Epoch 00187: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3610 - accuracy: 0.9717 - val_loss: 0.6000 - val_accuracy: 0.9225 - lr: 0.0025\n",
            "Epoch 188/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.9685\n",
            "Epoch 00188: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00188: ReduceLROnPlateau reducing learning rate to 0.002252839528955519.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3795 - accuracy: 0.9685 - val_loss: 0.5888 - val_accuracy: 0.9305 - lr: 0.0025\n",
            "Epoch 189/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.9698\n",
            "Epoch 00189: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.3673 - accuracy: 0.9698 - val_loss: 0.5320 - val_accuracy: 0.9385 - lr: 0.0023\n",
            "Epoch 190/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.9703\n",
            "Epoch 00190: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3706 - accuracy: 0.9703 - val_loss: 0.5748 - val_accuracy: 0.9332 - lr: 0.0023\n",
            "Epoch 191/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.9682\n",
            "Epoch 00191: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.0020275555551052095.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3679 - accuracy: 0.9682 - val_loss: 0.5338 - val_accuracy: 0.9465 - lr: 0.0023\n",
            "Epoch 192/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.9685\n",
            "Epoch 00192: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3680 - accuracy: 0.9685 - val_loss: 0.4973 - val_accuracy: 0.9385 - lr: 0.0020\n",
            "Epoch 193/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.9719\n",
            "Epoch 00193: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3631 - accuracy: 0.9719 - val_loss: 0.5537 - val_accuracy: 0.9439 - lr: 0.0020\n",
            "Epoch 194/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.9728\n",
            "Epoch 00194: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3610 - accuracy: 0.9728 - val_loss: 0.5707 - val_accuracy: 0.9305 - lr: 0.0020\n",
            "Epoch 195/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.9723\n",
            "Epoch 00195: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0018248000415042043.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3590 - accuracy: 0.9723 - val_loss: 0.5271 - val_accuracy: 0.9439 - lr: 0.0020\n",
            "Epoch 196/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.9728\n",
            "Epoch 00196: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3531 - accuracy: 0.9728 - val_loss: 0.5182 - val_accuracy: 0.9251 - lr: 0.0018\n",
            "Epoch 197/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.9705\n",
            "Epoch 00197: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3626 - accuracy: 0.9705 - val_loss: 0.4990 - val_accuracy: 0.9412 - lr: 0.0018\n",
            "Epoch 198/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.9703\n",
            "Epoch 00198: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.001642320037353784.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3611 - accuracy: 0.9703 - val_loss: 0.5118 - val_accuracy: 0.9358 - lr: 0.0018\n",
            "Epoch 199/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.9758\n",
            "Epoch 00199: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3531 - accuracy: 0.9758 - val_loss: 0.5848 - val_accuracy: 0.9305 - lr: 0.0016\n",
            "Epoch 200/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.9703\n",
            "Epoch 00200: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3620 - accuracy: 0.9703 - val_loss: 0.5185 - val_accuracy: 0.9332 - lr: 0.0016\n",
            "Epoch 201/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.9781\n",
            "Epoch 00201: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00201: ReduceLROnPlateau reducing learning rate to 0.0014780880650505424.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3458 - accuracy: 0.9781 - val_loss: 0.5077 - val_accuracy: 0.9385 - lr: 0.0016\n",
            "Epoch 202/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.9749\n",
            "Epoch 00202: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3515 - accuracy: 0.9749 - val_loss: 0.5059 - val_accuracy: 0.9412 - lr: 0.0015\n",
            "Epoch 203/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.9737\n",
            "Epoch 00203: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3547 - accuracy: 0.9737 - val_loss: 0.5245 - val_accuracy: 0.9439 - lr: 0.0015\n",
            "Epoch 204/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.9719\n",
            "Epoch 00204: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00204: ReduceLROnPlateau reducing learning rate to 0.001330279279500246.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3570 - accuracy: 0.9719 - val_loss: 0.5223 - val_accuracy: 0.9332 - lr: 0.0015\n",
            "Epoch 205/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.9762\n",
            "Epoch 00205: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3526 - accuracy: 0.9762 - val_loss: 0.5258 - val_accuracy: 0.9439 - lr: 0.0013\n",
            "Epoch 206/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.9710\n",
            "Epoch 00206: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3588 - accuracy: 0.9710 - val_loss: 0.5679 - val_accuracy: 0.9358 - lr: 0.0013\n",
            "Epoch 207/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.9760\n",
            "Epoch 00207: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00207: ReduceLROnPlateau reducing learning rate to 0.0011972513515502215.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3487 - accuracy: 0.9760 - val_loss: 0.5601 - val_accuracy: 0.9305 - lr: 0.0013\n",
            "Epoch 208/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.9774\n",
            "Epoch 00208: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3419 - accuracy: 0.9774 - val_loss: 0.5077 - val_accuracy: 0.9519 - lr: 0.0012\n",
            "Epoch 209/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.9705\n",
            "Epoch 00209: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.3581 - accuracy: 0.9705 - val_loss: 0.5079 - val_accuracy: 0.9412 - lr: 0.0012\n",
            "Epoch 210/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.9760\n",
            "Epoch 00210: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00210: ReduceLROnPlateau reducing learning rate to 0.0010775262373499573.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3459 - accuracy: 0.9760 - val_loss: 0.5146 - val_accuracy: 0.9492 - lr: 0.0012\n",
            "Epoch 211/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.9749\n",
            "Epoch 00211: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3496 - accuracy: 0.9749 - val_loss: 0.5004 - val_accuracy: 0.9492 - lr: 0.0011\n",
            "Epoch 212/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.9762\n",
            "Epoch 00212: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3460 - accuracy: 0.9762 - val_loss: 0.5226 - val_accuracy: 0.9412 - lr: 0.0011\n",
            "Epoch 213/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.9753\n",
            "Epoch 00213: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00213: ReduceLROnPlateau reducing learning rate to 0.0009697736240923405.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3469 - accuracy: 0.9753 - val_loss: 0.5831 - val_accuracy: 0.9305 - lr: 0.0011\n",
            "Epoch 214/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.9753\n",
            "Epoch 00214: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3468 - accuracy: 0.9753 - val_loss: 0.5109 - val_accuracy: 0.9385 - lr: 9.6977e-04\n",
            "Epoch 215/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.9758\n",
            "Epoch 00215: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3453 - accuracy: 0.9758 - val_loss: 0.5392 - val_accuracy: 0.9305 - lr: 9.6977e-04\n",
            "Epoch 216/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.9762\n",
            "Epoch 00216: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00216: ReduceLROnPlateau reducing learning rate to 0.0008727962616831064.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3468 - accuracy: 0.9762 - val_loss: 0.5076 - val_accuracy: 0.9465 - lr: 9.6977e-04\n",
            "Epoch 217/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.9767\n",
            "Epoch 00217: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3443 - accuracy: 0.9767 - val_loss: 0.5531 - val_accuracy: 0.9412 - lr: 8.7280e-04\n",
            "Epoch 218/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.9760\n",
            "Epoch 00218: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3471 - accuracy: 0.9760 - val_loss: 0.5188 - val_accuracy: 0.9385 - lr: 8.7280e-04\n",
            "Epoch 219/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.9771\n",
            "Epoch 00219: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.0007855166564695537.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3435 - accuracy: 0.9771 - val_loss: 0.5324 - val_accuracy: 0.9412 - lr: 8.7280e-04\n",
            "Epoch 220/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.9721\n",
            "Epoch 00220: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3501 - accuracy: 0.9721 - val_loss: 0.5488 - val_accuracy: 0.9465 - lr: 7.8552e-04\n",
            "Epoch 221/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.9787\n",
            "Epoch 00221: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3383 - accuracy: 0.9787 - val_loss: 0.4827 - val_accuracy: 0.9385 - lr: 7.8552e-04\n",
            "Epoch 222/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.9792\n",
            "Epoch 00222: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3379 - accuracy: 0.9792 - val_loss: 0.5320 - val_accuracy: 0.9465 - lr: 7.8552e-04\n",
            "Epoch 223/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.9762\n",
            "Epoch 00223: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3417 - accuracy: 0.9762 - val_loss: 0.5046 - val_accuracy: 0.9439 - lr: 7.8552e-04\n",
            "Epoch 224/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.9767\n",
            "Epoch 00224: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3490 - accuracy: 0.9767 - val_loss: 0.4772 - val_accuracy: 0.9492 - lr: 7.8552e-04\n",
            "Epoch 225/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.9753\n",
            "Epoch 00225: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3454 - accuracy: 0.9753 - val_loss: 0.5209 - val_accuracy: 0.9385 - lr: 7.8552e-04\n",
            "Epoch 226/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.9767\n",
            "Epoch 00226: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3425 - accuracy: 0.9767 - val_loss: 0.5504 - val_accuracy: 0.9251 - lr: 7.8552e-04\n",
            "Epoch 227/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.9746\n",
            "Epoch 00227: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00227: ReduceLROnPlateau reducing learning rate to 0.0007069649698678405.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3475 - accuracy: 0.9746 - val_loss: 0.5143 - val_accuracy: 0.9465 - lr: 7.8552e-04\n",
            "Epoch 228/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.9744\n",
            "Epoch 00228: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3465 - accuracy: 0.9744 - val_loss: 0.5569 - val_accuracy: 0.9439 - lr: 7.0696e-04\n",
            "Epoch 229/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.9755\n",
            "Epoch 00229: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3387 - accuracy: 0.9755 - val_loss: 0.5696 - val_accuracy: 0.9358 - lr: 7.0696e-04\n",
            "Epoch 230/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.9746\n",
            "Epoch 00230: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00230: ReduceLROnPlateau reducing learning rate to 0.0006362684885971248.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3421 - accuracy: 0.9746 - val_loss: 0.5252 - val_accuracy: 0.9412 - lr: 7.0696e-04\n",
            "Epoch 231/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.9785\n",
            "Epoch 00231: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3417 - accuracy: 0.9785 - val_loss: 0.5322 - val_accuracy: 0.9278 - lr: 6.3627e-04\n",
            "Epoch 232/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.9778\n",
            "Epoch 00232: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3364 - accuracy: 0.9778 - val_loss: 0.5221 - val_accuracy: 0.9439 - lr: 6.3627e-04\n",
            "Epoch 233/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.9762\n",
            "Epoch 00233: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00233: ReduceLROnPlateau reducing learning rate to 0.0005726416187826544.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3432 - accuracy: 0.9762 - val_loss: 0.5260 - val_accuracy: 0.9439 - lr: 6.3627e-04\n",
            "Epoch 234/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.9746\n",
            "Epoch 00234: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3480 - accuracy: 0.9746 - val_loss: 0.5058 - val_accuracy: 0.9492 - lr: 5.7264e-04\n",
            "Epoch 235/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.9755\n",
            "Epoch 00235: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3447 - accuracy: 0.9755 - val_loss: 0.5055 - val_accuracy: 0.9305 - lr: 5.7264e-04\n",
            "Epoch 236/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.9792\n",
            "Epoch 00236: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00236: ReduceLROnPlateau reducing learning rate to 0.0005153774516656995.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3321 - accuracy: 0.9792 - val_loss: 0.5390 - val_accuracy: 0.9385 - lr: 5.7264e-04\n",
            "Epoch 237/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.9746\n",
            "Epoch 00237: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3452 - accuracy: 0.9746 - val_loss: 0.5367 - val_accuracy: 0.9465 - lr: 5.1538e-04\n",
            "Epoch 238/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.9755\n",
            "Epoch 00238: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3456 - accuracy: 0.9755 - val_loss: 0.4977 - val_accuracy: 0.9519 - lr: 5.1538e-04\n",
            "Epoch 239/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.9755\n",
            "Epoch 00239: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00239: ReduceLROnPlateau reducing learning rate to 0.00046383969602175056.\n",
            "35/35 [==============================] - 69s 2s/step - loss: 0.3424 - accuracy: 0.9755 - val_loss: 0.5260 - val_accuracy: 0.9492 - lr: 5.1538e-04\n",
            "Epoch 240/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.9778\n",
            "Epoch 00240: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3382 - accuracy: 0.9778 - val_loss: 0.5350 - val_accuracy: 0.9412 - lr: 4.6384e-04\n",
            "Epoch 241/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.9730\n",
            "Epoch 00241: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3504 - accuracy: 0.9730 - val_loss: 0.5175 - val_accuracy: 0.9519 - lr: 4.6384e-04\n",
            "Epoch 242/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.9806\n",
            "Epoch 00242: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00242: ReduceLROnPlateau reducing learning rate to 0.0004174557368969545.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3288 - accuracy: 0.9806 - val_loss: 0.5264 - val_accuracy: 0.9439 - lr: 4.6384e-04\n",
            "Epoch 243/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.9769\n",
            "Epoch 00243: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3401 - accuracy: 0.9769 - val_loss: 0.5134 - val_accuracy: 0.9439 - lr: 4.1746e-04\n",
            "Epoch 244/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.9771\n",
            "Epoch 00244: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3419 - accuracy: 0.9771 - val_loss: 0.5108 - val_accuracy: 0.9439 - lr: 4.1746e-04\n",
            "Epoch 245/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.9758\n",
            "Epoch 00245: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00245: ReduceLROnPlateau reducing learning rate to 0.00037571016582660377.\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3459 - accuracy: 0.9758 - val_loss: 0.5069 - val_accuracy: 0.9439 - lr: 4.1746e-04\n",
            "Epoch 246/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.9799\n",
            "Epoch 00246: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3304 - accuracy: 0.9799 - val_loss: 0.5542 - val_accuracy: 0.9332 - lr: 3.7571e-04\n",
            "Epoch 247/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.9774\n",
            "Epoch 00247: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3379 - accuracy: 0.9774 - val_loss: 0.5037 - val_accuracy: 0.9465 - lr: 3.7571e-04\n",
            "Epoch 248/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.9774\n",
            "Epoch 00248: val_accuracy did not improve from 0.95187\n",
            "\n",
            "Epoch 00248: ReduceLROnPlateau reducing learning rate to 0.0003381391492439434.\n",
            "35/35 [==============================] - 67s 2s/step - loss: 0.3362 - accuracy: 0.9774 - val_loss: 0.5472 - val_accuracy: 0.9385 - lr: 3.7571e-04\n",
            "Epoch 249/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.9744\n",
            "Epoch 00249: val_accuracy did not improve from 0.95187\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.3434 - accuracy: 0.9744 - val_loss: 0.5302 - val_accuracy: 0.9358 - lr: 3.3814e-04\n",
            "Epoch 250/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.9769\n",
            "Epoch 00250: val_accuracy improved from 0.95187 to 0.95455, saving model to best_model_vgg16_plant_seedlings_attempt_3\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16_plant_seedlings_attempt_3/assets\n",
            "35/35 [==============================] - 71s 2s/step - loss: 0.3374 - accuracy: 0.9769 - val_loss: 0.5353 - val_accuracy: 0.9545 - lr: 3.3814e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "0iMb8pSI_ICn",
        "outputId": "c4f3eead-7457-482f-d769-d087b401368c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(history.history['val_loss'],label='Test loss')\n",
        "plt.plot(history.history['loss'],label='Train loss')\n",
        "plt.title('Loss curve for improved vgg16 model')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(history.history['val_accuracy'],label = 'Test accuracy')\n",
        "plt.plot(history.history['accuracy'],label = 'Train accuracy')\n",
        "plt.title('Accuracy curve for improved vgg16 model')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu_OHpXKw-N6",
        "outputId": "7fd0445f-b526-47ab-8ad9-9341703a8c89"
      },
      "source": [
        "model = tf.keras.models.load_model('best_model_vgg19_plant_seedlings_attempt_1')\n",
        "print(len(test_generator))\n",
        "seedlings_types = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n",
        "                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n",
        "                \"Sugar beet\"]\n",
        "predictions = model.predict(test_generator, steps=test_generator.samples)\n",
        "\n",
        "class_list = []\n",
        "\n",
        "for i in range(0, predictions.shape[0]):\n",
        "  y_class = predictions[i, :].argmax(axis=-1)\n",
        "  class_list += [seedlings_types[y_class]]\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['file'] = test_generator.filenames\n",
        "submission['file'] = submission['file'].str.replace(r'test/', '')\n",
        "submission['species'] = class_list\n",
        "\n",
        "submission.to_csv('submission_vgg_10_attempt_1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wgEWpFCYiVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}