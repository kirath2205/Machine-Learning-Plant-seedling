{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant_seedlings_project_attempt_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3FACW81e+uhPcoL5KK5fF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Machine-Learning-Plant-seedling/blob/main/vgg_16_notebook_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgwrFHgFx3f8"
      },
      "source": [
        "#Importing the requisite libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jLKQK3N4V9-"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ol4ui5dfu1"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6RDojARx72m"
      },
      "source": [
        "#Function to generate the train , test and validation generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRsevFzr5OUZ"
      },
      "source": [
        "def define_generators():\n",
        "  height = 250\n",
        "  width = 250\n",
        "  batch_size = 128\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=360,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        shear_range=0.3,\n",
        "        zoom_range=0.5,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.08, \n",
        "    )\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "        directory='Documents/train',\n",
        "        target_size=(width, height),\n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        class_mode=\"categorical\",\n",
        "        subset='training',\n",
        "    )\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_directory(\n",
        "        directory='Documents/train',\n",
        "        target_size=(width, height),\n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        class_mode=\"categorical\",\n",
        "        subset='validation',\n",
        "    )\n",
        "\n",
        "  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "        directory='Documents/',\n",
        "        classes=['test'],\n",
        "        target_size=(width, height),\n",
        "        batch_size=1,\n",
        "        color_mode='rgb',\n",
        "        shuffle=False,\n",
        "        class_mode='categorical')\n",
        "\n",
        "  return train_generator, validation_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxqR8Mm4yBqA"
      },
      "source": [
        "#VGG-16 model creation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAUpGw6D6ip9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def define_model_vgg16_improvement(image_shape,total_classes):\n",
        "  print(image_shape[2])\n",
        "\n",
        "  model = Sequential()\n",
        "  weight_decay = 0.0005\n",
        "  learning_rate = 0.1\n",
        "  lr_decay = 1e-6\n",
        "  lr_drop = 20\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), padding='same',input_shape=image_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhkuqM9LyG9E"
      },
      "source": [
        "#Function to train the model, added several callbacks - early stopping , model checkpoint and learning rate decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNZV6W7O9s2O"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(model , train_generator,validation_generator,epochs=10):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg16_plant_seedlings_attempt_3', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.9, patience = 3, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 40)\n",
        "  ]\n",
        "  history=model.fit(train_generator, epochs = epochs,callbacks = callbacks, verbose = 1,validation_data = validation_generator)\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ35ZSAIbuNm"
      },
      "source": [
        "train_generator, validation_generator, test_generator  = define_generators()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An9BB54h9xY2"
      },
      "source": [
        "improved_model = define_model_vgg16_improvement((250, 250 , 3),12)\n",
        "history = train_model_vgg16(improved_model , train_generator , validation_generator , epochs=250 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzxY1uM4yd6J"
      },
      "source": [
        "#Plotting the train and validation accuracy and loss curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iMb8pSI_ICn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(history.history['val_loss'],label='Test loss')\n",
        "plt.plot(history.history['loss'],label='Train loss')\n",
        "plt.title('Loss curve for improved vgg16 model')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(history.history['val_accuracy'],label = 'Test accuracy')\n",
        "plt.plot(history.history['accuracy'],label = 'Train accuracy')\n",
        "plt.title('Accuracy curve for improved vgg16 model')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYNdgJMqyixB"
      },
      "source": [
        "#Creating the submission file for kaggle but making predictions on the test data using the loaded weights of the best model found during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu_OHpXKw-N6"
      },
      "source": [
        "model = tf.keras.models.load_model('best_model_vgg16_plant_seedlings_attempt_3')\n",
        "print(len(test_generator))\n",
        "seedlings_types = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n",
        "                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n",
        "                \"Sugar beet\"]\n",
        "predictions = model.predict(test_generator, steps=test_generator.samples)\n",
        "\n",
        "class_list = []\n",
        "\n",
        "for i in range(0, predictions.shape[0]):\n",
        "  y_class = predictions[i, :].argmax(axis=-1)\n",
        "  class_list += [seedlings_types[y_class]]\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['file'] = test_generator.filenames\n",
        "submission['file'] = submission['file'].str.replace(r'test/', '')\n",
        "submission['species'] = class_list\n",
        "\n",
        "submission.to_csv('submission_attempt_3.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wgEWpFCYiVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}